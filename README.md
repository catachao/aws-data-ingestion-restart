# ğŸ› ï¸ AWS Data Ingestion Pipeline - Real-Time Architecture

Este repositorio contiene el cÃ³digo y scripts necesarios para implementar un pipeline de ingesta de datos en AWS utilizando servicios como Amazon RDS, AWS DMS, AWS Glue, Amazon Redshift y Power BI. La soluciÃ³n estÃ¡ diseÃ±ada para permitir una carga y transformaciÃ³n eficiente de datos con manejo de cambios mediante Slowly Changing Dimensions (SCD Tipo 2).

## ğŸ§± Arquitectura General

![Arquitectura AWS Data Pipeline](assets/aws_architecture.gif)

![Diagrama en Power Bi](assets/power_bi_diagram.png)

### Componentes Clave

- **Amazon RDS**: Origen de los datos (base de datos transaccional).
- **AWS Lambda**: Automatiza disparadores para procesos de migraciÃ³n.
- **AWS DMS**: Realiza la migraciÃ³n de datos de RDS hacia S3.
- **Amazon S3 (Bronze / Silver)**: Almacenamiento por capas de datos sin procesar y parcialmente transformados.
- **AWS Glue**: Realiza transformaciones ETL sobre los datos.
- **Amazon Redshift**: AlmacÃ©n de datos donde se ejecutan Stored Procedures con lÃ³gica SCD Tipo 2.
- **AWS Step Functions**: OrquestaciÃ³n de los procesos ETL.
- **Power BI**: Conectado a Redshift para visualizaciÃ³n analÃ­tica.

---

## ğŸ“ Estructura del Repositorio

```bash
aws-data-ingestion-restart/
â”‚
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ aws_architecture.gif          # Diagrama animado de la arquitectura
â”‚
â”œâ”€â”€ glue-jobs/
â”‚   â”œâ”€â”€ load_jobs/
â”‚   â”‚   â””â”€â”€ data-engineering-project-load-orders_job.py
â”‚   â””â”€â”€ transform_jobs/
â”‚       â”œâ”€â”€ raw_customer_etl_job.py
â”‚       â”œâ”€â”€ raw_orderdetails_etl_job.py
â”‚       â”œâ”€â”€ raw_orders_etl_job.py
â”‚       â””â”€â”€ raw_product_etl_job.py
â”‚
â”œâ”€â”€ lambda-function/
â”‚   â””â”€â”€ lambda_function.py
â”‚
â”œâ”€â”€ rds/
â”‚   â””â”€â”€ mysql_source_ddl.sql
â”‚
â”œâ”€â”€ redshift/
â”‚   â”œâ”€â”€ DDL/
â”‚   â”‚   â”œâ”€â”€ customer_setup_sql.sql
â”‚   â”‚   â”œâ”€â”€ mv_sales_mart.sql
â”‚   â”‚   â”œâ”€â”€ order_details_setup_sql.sql
â”‚   â”‚   â”œâ”€â”€ orders_setup_sql.sql
â”‚   â”‚   â”œâ”€â”€ products_setup_sql.sql
â”‚   â”‚   â””â”€â”€ schema_database.sql
â”‚   â””â”€â”€ SP/
â”‚       â”œâ”€â”€ customer_dim_sp.sql
â”‚       â””â”€â”€ products_dim_sp.sql
â”‚
â”œâ”€â”€ step-functions/
â”‚   â””â”€â”€ MyStateMachine.json
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ README.mdgit
```

---

## âš™ï¸ CÃ³mo desplegar

1. **Configurar RDS y cargar esquema fuente**  
   Ejecutar el script `mysql_source_ddl.sql` en una instancia MySQL de Amazon RDS.

2. **Migrar datos con AWS DMS**  
   Crear endpoints de origen y destino, y configurar el *Database Migration Workflow Job*.

3. **Cargar datos a S3 y transformarlos**  
   Ejecutar los Glue Jobs en `glue-jobs/` para las capas Bronze y Silver.

4. **Crear estructura en Redshift**  
   Usar los scripts de `redshift/DDL` para crear tablas y vistas necesarias.

5. **Aplicar lÃ³gica SCD**  
   Ejecutar los Stored Procedures en `redshift/SP`.

6. **Visualizar en Power BI**  
   Conectar Power BI a Amazon Redshift para reportes y dashboards.

---

## ğŸ§  TecnologÃ­as Utilizadas

- **AWS DMS**
- **AWS Lambda**
- **AWS Glue**
- **Amazon S3**
- **Amazon Redshift**
- **AWS Step Functions**
- **AWS EventBridge**
- **Power BI**

---

## ğŸ“Š Caso de Uso

Esta arquitectura permite a los analistas de datos tener una vista consolidada y actualizada de datos operacionales, con trazabilidad histÃ³rica gracias a la implementaciÃ³n de Slowly Changing Dimensions (Tipo 2).

---

## âœï¸ Autor

**Cesar Atachao**  
Ingeniero de Sistemas | Cloud & Data Engineering Enthusiast
